#!/usr/bin/env node
/**
 * Comprehensive BURC Sync - Captures ALL worksheets from all BURC files
 *
 * Files synced:
 * - 2026 APAC Performance.xlsx (36 sheets)
 * - 2025 APAC Performance.xlsx (51 sheets)
 * - 2024 APAC Performance.xlsx (36 sheets)
 * - 2023 12 BURC File.xlsb (17 sheets) - via Python
 */

import { createClient } from '@supabase/supabase-js'
import XLSX from 'xlsx'
import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'
import { execSync } from 'child_process'
import dotenv from 'dotenv'
import { BURC_BASE, requireOneDrive } from './lib/onedrive-paths.mjs'

requireOneDrive()

const __dirname = path.dirname(fileURLToPath(import.meta.url))
dotenv.config({ path: path.join(__dirname, '..', '.env.local') })

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
)

const BURC_BASE = BURC_BASE

const MONTHS = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

// Track sync statistics
const stats = {
  attrition: 0,
  headcount: 0,
  monthlyEbita: 0,
  monthlyOpex: 0,
  revenueDetail: 0,
  bookings: 0,
  risksOpportunities: 0,
  psMargins: 0,
  supportRenewals: 0
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

function parseNumber(val) {
  if (val === null || val === undefined || val === '' || val === '-') return 0
  if (typeof val === 'number') return val
  const str = String(val).replace(/[$,()]/g, '').trim()
  if (str.startsWith('(') || str.startsWith('-')) {
    return -Math.abs(parseFloat(str.replace(/[()]/g, '')) || 0)
  }
  return parseFloat(str) || 0
}

function getSheetData(workbook, sheetName) {
  const sheet = workbook.Sheets[sheetName]
  if (!sheet) return null
  return XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })
}

function findHeaderRow(data, keywords) {
  for (let i = 0; i < Math.min(20, data.length); i++) {
    const row = data[i]
    if (!row) continue
    const rowStr = row.map(c => String(c).toLowerCase()).join(' ')
    if (keywords.some(kw => rowStr.includes(kw.toLowerCase()))) {
      return i
    }
  }
  return -1
}

// ============================================================================
// ATTRITION DATA SYNC
// ============================================================================

async function syncAttrition(workbook, year, sourceFile) {
  console.log(`\n  üìâ Syncing Attrition data for ${year}...`)

  const sheet = workbook.Sheets['Attrition']
  if (!sheet) {
    console.log('     No Attrition sheet found')
    return
  }

  const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })
  const headerRow = findHeaderRow(data, ['client', 'customer', 'product', 'revenue', 'risk'])

  if (headerRow === -1) {
    console.log('     Could not find header row')
    return
  }

  const headers = data[headerRow].map(h => String(h).toLowerCase().trim())
  const clientCol = headers.findIndex(h => h.includes('client') || h.includes('customer'))
  const productCol = headers.findIndex(h => h.includes('product'))
  const revenueCol = headers.findIndex(h => h.includes('revenue') || h.includes('value') || h.includes('arr'))
  const statusCol = headers.findIndex(h => h.includes('status'))
  const reasonCol = headers.findIndex(h => h.includes('reason'))

  const records = []

  for (let i = headerRow + 1; i < data.length; i++) {
    const row = data[i]
    if (!row || !row[clientCol]) continue

    const clientName = String(row[clientCol]).trim()
    if (!clientName || clientName.toLowerCase() === 'total') continue

    records.push({
      fiscal_year: year,
      client_name: clientName,
      product: productCol >= 0 ? String(row[productCol] || '').trim() : null,
      revenue_at_risk: revenueCol >= 0 ? parseNumber(row[revenueCol]) : 0,
      status: statusCol >= 0 ? String(row[statusCol] || '').trim() : null,
      reason: reasonCol >= 0 ? String(row[reasonCol] || '').trim() : null,
      source_file: sourceFile
    })
  }

  if (records.length > 0) {
    // Delete existing records for this year
    await supabase.from('burc_attrition').delete().eq('fiscal_year', year)

    const { error } = await supabase.from('burc_attrition').insert(records)
    if (error) {
      console.log(`     Error: ${error.message}`)
    } else {
      console.log(`     ‚úÖ Synced ${records.length} attrition records`)
      stats.attrition += records.length
    }
  }
}

// ============================================================================
// HEADCOUNT DATA SYNC
// ============================================================================

async function syncHeadcount(workbook, year, sourceFile) {
  console.log(`\n  üë• Syncing Headcount data for ${year}...`)

  const sheet = workbook.Sheets['Headcount Summary']
  if (!sheet) {
    console.log('     No Headcount Summary sheet found')
    return
  }

  const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })

  // This sheet has months in row 0, departments in column 0
  // Row 0: empty, Jan, Feb, Mar, ...
  // Row 1: Grand Total, value, value, ...
  // Row 2: General and Admin, value, value, ...
  const headerRow = data[0]
  if (!headerRow) {
    console.log('     Empty sheet')
    return
  }

  // Find month columns
  const monthCols = {}
  headerRow.forEach((h, i) => {
    const hStr = String(h).trim()
    MONTHS.forEach((m, mi) => {
      if (hStr.includes(m)) {
        monthCols[mi + 1] = i
      }
    })
  })

  if (Object.keys(monthCols).length === 0) {
    console.log('     Could not find month columns')
    return
  }

  const records = []

  // Skip row 0 (headers) and row 1 (Grand Total), start from row 2
  for (let i = 2; i < data.length; i++) {
    const row = data[i]
    if (!row || !row[0]) continue

    const dept = String(row[0]).trim()
    if (!dept || dept.toLowerCase() === 'total' || dept.toLowerCase() === 'grand total') continue

    // Get values for each month
    for (const [monthNum, colIdx] of Object.entries(monthCols)) {
      const value = parseNumber(row[colIdx])
      if (value === 0) continue

      records.push({
        fiscal_year: year,
        month_num: parseInt(monthNum),
        department: dept,
        role_category: null,
        headcount: Math.round(value), // Headcount is usually whole numbers
        fte: value,
        cost: 0,
        source_file: sourceFile
      })
    }
  }

  if (records.length > 0) {
    await supabase.from('burc_headcount').delete().eq('fiscal_year', year)

    const { error } = await supabase.from('burc_headcount').insert(records)
    if (error) {
      console.log(`     Error: ${error.message}`)
    } else {
      console.log(`     ‚úÖ Synced ${records.length} headcount records`)
      stats.headcount += records.length
    }
  } else {
    console.log('     No headcount data found')
  }
}

// ============================================================================
// MONTHLY EBITA SYNC
// ============================================================================

async function syncMonthlyEbita(workbook, year, sourceFile) {
  console.log(`\n  üìä Syncing Monthly EBITA for ${year}...`)

  const sheet = workbook.Sheets['APAC BURC - Monthly EBITA']
  if (!sheet) {
    console.log('     No APAC BURC - Monthly EBITA sheet found')
    return
  }

  const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })

  // Find month columns
  const headerRow = data.findIndex(row =>
    row && row.some(cell => MONTHS.some(m => String(cell).includes(m)))
  )

  if (headerRow === -1) {
    console.log('     Could not find month headers')
    return
  }

  const headers = data[headerRow]
  const monthCols = {}

  headers.forEach((h, i) => {
    const hStr = String(h).trim()
    MONTHS.forEach((m, mi) => {
      if (hStr.includes(m)) {
        monthCols[mi + 1] = i
      }
    })
  })

  // Find metric rows
  const records = []
  const metricNames = ['Net Revenue', 'Total Revenue', 'COGS', 'Gross Margin', 'OPEX', 'EBITA']

  for (let i = headerRow + 1; i < data.length; i++) {
    const row = data[i]
    if (!row || !row[0]) continue

    const metricName = String(row[0]).trim()
    if (!metricNames.some(m => metricName.toLowerCase().includes(m.toLowerCase()))) continue

    for (const [monthNum, colIdx] of Object.entries(monthCols)) {
      const value = parseNumber(row[colIdx])
      if (value === 0) continue

      // Map to appropriate column based on metric name
      const record = {
        fiscal_year: year,
        month_num: parseInt(monthNum),
        month_name: MONTHS[parseInt(monthNum) - 1],
        revenue: 0,
        cogs: 0,
        gross_margin: 0,
        opex: 0,
        ebita: 0,
        ebita_percent: 0,
        source_file: sourceFile
      }

      if (metricName.toLowerCase().includes('revenue')) record.revenue = value
      if (metricName.toLowerCase().includes('cogs')) record.cogs = value
      if (metricName.toLowerCase().includes('gross')) record.gross_margin = value
      if (metricName.toLowerCase().includes('opex')) record.opex = value
      if (metricName.toLowerCase().includes('ebita') && !metricName.includes('%')) record.ebita = value
      if (metricName.toLowerCase().includes('ebita') && metricName.includes('%')) record.ebita_percent = value

      records.push(record)
    }
  }

  if (records.length > 0) {
    // Consolidate records by month
    const consolidated = {}
    for (const rec of records) {
      const key = `${rec.fiscal_year}-${rec.month_num}`
      if (!consolidated[key]) {
        consolidated[key] = { ...rec }
      } else {
        // Merge values
        if (rec.revenue) consolidated[key].revenue = rec.revenue
        if (rec.cogs) consolidated[key].cogs = rec.cogs
        if (rec.gross_margin) consolidated[key].gross_margin = rec.gross_margin
        if (rec.opex) consolidated[key].opex = rec.opex
        if (rec.ebita) consolidated[key].ebita = rec.ebita
        if (rec.ebita_percent) consolidated[key].ebita_percent = rec.ebita_percent
      }
    }

    const finalRecords = Object.values(consolidated)

    await supabase.from('burc_monthly_ebita').delete().eq('fiscal_year', year)

    const { error } = await supabase.from('burc_monthly_ebita').insert(finalRecords)
    if (error) {
      console.log(`     Error: ${error.message}`)
    } else {
      console.log(`     ‚úÖ Synced ${finalRecords.length} monthly EBITA records`)
      stats.monthlyEbita += finalRecords.length
    }
  }
}

// ============================================================================
// MONTHLY OPEX SYNC
// ============================================================================

async function syncMonthlyOpex(workbook, year, sourceFile) {
  console.log(`\n  üí∞ Syncing Monthly OPEX for ${year}...`)

  let sheet = workbook.Sheets['APAC BURC - Monthly OPEX Comp'] || workbook.Sheets['OPEX']
  if (!sheet) {
    console.log('     No OPEX sheet found')
    return
  }

  const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })

  // Find month columns
  const headerRow = data.findIndex(row =>
    row && row.some(cell => MONTHS.some(m => String(cell).includes(m)))
  )

  if (headerRow === -1) {
    console.log('     Could not find month headers')
    return
  }

  const headers = data[headerRow]
  const monthCols = {}

  headers.forEach((h, i) => {
    const hStr = String(h).trim()
    MONTHS.forEach((m, mi) => {
      if (hStr.includes(m)) {
        monthCols[mi + 1] = i
      }
    })
  })

  const records = []

  for (let i = headerRow + 1; i < data.length; i++) {
    const row = data[i]
    if (!row || !row[0]) continue

    const category = String(row[0]).trim()
    if (!category || category.toLowerCase() === 'total' || category.toLowerCase().includes('grand')) continue

    for (const [monthNum, colIdx] of Object.entries(monthCols)) {
      const amount = parseNumber(row[colIdx])
      if (amount === 0) continue

      records.push({
        fiscal_year: year,
        month_num: parseInt(monthNum),
        month_name: MONTHS[parseInt(monthNum) - 1],
        category: category,
        amount: amount,
        source_file: sourceFile
      })
    }
  }

  if (records.length > 0) {
    // De-duplicate records by aggregating amounts for same month/category
    const consolidated = {}
    for (const rec of records) {
      const key = `${rec.fiscal_year}-${rec.month_num}-${rec.category}`
      if (!consolidated[key]) {
        consolidated[key] = { ...rec }
      } else {
        // Sum amounts for duplicates
        consolidated[key].amount += rec.amount
      }
    }

    const finalRecords = Object.values(consolidated)

    await supabase.from('burc_monthly_opex').delete().eq('fiscal_year', year)

    const { error } = await supabase.from('burc_monthly_opex').insert(finalRecords)
    if (error) {
      console.log(`     Error: ${error.message}`)
    } else {
      console.log(`     ‚úÖ Synced ${finalRecords.length} monthly OPEX records`)
      stats.monthlyOpex += finalRecords.length
    }
  }
}

// ============================================================================
// REVENUE DETAIL SYNC (SW, PS, Maint, HW)
// ============================================================================

async function syncRevenueDetail(workbook, year, sourceFile) {
  console.log(`\n  üìà Syncing Revenue Detail for ${year}...`)

  const revenueSheets = {
    'SW': ['SW', 'SW Pivot'],
    'PS': ['PS', 'PS Pivot'],
    'Maint': ['Maint', 'Maint Pivot', 'Maintenance and Subscription'],
    'HW': ['HW', 'HW Pivot']
  }

  const records = []

  for (const [revType, sheetNames] of Object.entries(revenueSheets)) {
    for (const sheetName of sheetNames) {
      const sheet = workbook.Sheets[sheetName]
      if (!sheet) continue

      console.log(`     Reading ${sheetName}...`)
      const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })

      // Look for client/deal name column and quarterly values
      const headerRow = findHeaderRow(data, ['client', 'customer', 'deal', 'product', 'description'])
      if (headerRow === -1) continue

      const headers = data[headerRow].map(h => String(h).toLowerCase().trim())
      const nameCol = headers.findIndex(h =>
        h.includes('client') || h.includes('customer') || h.includes('deal') || h.includes('description')
      )

      // Find Q1-Q4 or monthly columns
      const q1Col = headers.findIndex(h => h.includes('q1') || h.includes('jul') || h.includes('quarter 1'))
      const q2Col = headers.findIndex(h => h.includes('q2') || h.includes('oct') || h.includes('quarter 2'))
      const q3Col = headers.findIndex(h => h.includes('q3') || h.includes('jan') || h.includes('quarter 3'))
      const q4Col = headers.findIndex(h => h.includes('q4') || h.includes('apr') || h.includes('quarter 4'))
      const totalCol = headers.findIndex(h => h.includes('total') || h.includes('fy'))

      const categoryCol = headers.findIndex(h => h.includes('category') || h.includes('type') || h.includes('status'))

      for (let i = headerRow + 1; i < Math.min(data.length, headerRow + 200); i++) {
        const row = data[i]
        if (!row || !row[nameCol >= 0 ? nameCol : 0]) continue

        const name = String(row[nameCol >= 0 ? nameCol : 0]).trim()
        if (!name || name.toLowerCase() === 'total' || name.toLowerCase().includes('grand')) continue

        records.push({
          fiscal_year: year,
          revenue_type: revType,
          client_name: name,
          deal_name: null,
          product: null,
          q1_value: q1Col >= 0 ? parseNumber(row[q1Col]) : 0,
          q2_value: q2Col >= 0 ? parseNumber(row[q2Col]) : 0,
          q3_value: q3Col >= 0 ? parseNumber(row[q3Col]) : 0,
          q4_value: q4Col >= 0 ? parseNumber(row[q4Col]) : 0,
          fy_total: totalCol >= 0 ? parseNumber(row[totalCol]) : 0,
          category: categoryCol >= 0 ? String(row[categoryCol] || '').trim() : null,
          source_sheet: sheetName,
          source_file: sourceFile
        })
      }

      break // Only process first found sheet for each type
    }
  }

  if (records.length > 0) {
    await supabase.from('burc_revenue_detail').delete().eq('fiscal_year', year)

    // Insert in batches
    const batchSize = 100
    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize)
      const { error } = await supabase.from('burc_revenue_detail').insert(batch)
      if (error) {
        console.log(`     Error batch ${i}: ${error.message}`)
      }
    }

    console.log(`     ‚úÖ Synced ${records.length} revenue detail records`)
    stats.revenueDetail += records.length
  }
}

// ============================================================================
// SUPPORT RENEWALS SYNC
// ============================================================================

async function syncSupportRenewals(workbook, year, sourceFile) {
  console.log(`\n  üîÑ Syncing Support Renewals for ${year}...`)

  const sheet = workbook.Sheets['Support Renewals']
  if (!sheet) {
    console.log('     No Support Renewals sheet found')
    return
  }

  const data = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' })
  const headerRow = findHeaderRow(data, ['client', 'customer', 'contract', 'value', 'renewal'])

  if (headerRow === -1) {
    console.log('     Could not find header row')
    return
  }

  const headers = data[headerRow].map(h => String(h).toLowerCase().trim())
  const clientCol = headers.findIndex(h => h.includes('client') || h.includes('customer'))
  const valueCol = headers.findIndex(h => h.includes('value') || h.includes('amount') || h.includes('arr'))
  const dateCol = headers.findIndex(h => h.includes('date') || h.includes('renewal'))
  const statusCol = headers.findIndex(h => h.includes('status'))

  const records = []

  for (let i = headerRow + 1; i < data.length; i++) {
    const row = data[i]
    if (!row || !row[clientCol >= 0 ? clientCol : 0]) continue

    const clientName = String(row[clientCol >= 0 ? clientCol : 0]).trim()
    if (!clientName || clientName.toLowerCase() === 'total') continue

    records.push({
      fiscal_year: year,
      client_name: clientName,
      contract_value: valueCol >= 0 ? parseNumber(row[valueCol]) : 0,
      renewal_date: dateCol >= 0 && row[dateCol] ? new Date(row[dateCol]).toISOString().split('T')[0] : null,
      renewal_status: statusCol >= 0 ? String(row[statusCol] || '').trim() : null,
      source_file: sourceFile
    })
  }

  if (records.length > 0) {
    await supabase.from('burc_support_renewals').delete().eq('fiscal_year', year)

    const { error } = await supabase.from('burc_support_renewals').insert(records)
    if (error) {
      console.log(`     Error: ${error.message}`)
    } else {
      console.log(`     ‚úÖ Synced ${records.length} support renewal records`)
      stats.supportRenewals += records.length
    }
  }
}

// ============================================================================
// 2023 XLSB SYNC (via Python)
// ============================================================================

async function sync2023Xlsb() {
  console.log('\nüì¶ Syncing 2023 XLSB data via Python...')

  const xlsbPath = `${BURC_BASE}/2023/Dec 23/2023 12 BURC File.xlsb`
  if (!fs.existsSync(xlsbPath)) {
    console.log('   ‚ùå 2023 XLSB file not found')
    return
  }

  // Create Python script to extract all data
  const pythonScript = `
import json
from pyxlsb import open_workbook

XLSB_FILE = '${xlsbPath}'
OUTPUT_FILE = '/tmp/burc-2023-all-data.json'

data = {
    'fiscal_year': 2023,
    'sheets': {},
    'summary': []
}

try:
    with open_workbook(XLSB_FILE) as wb:
        for sheet_name in wb.sheets:
            print(f'Reading {sheet_name}...')
            try:
                with wb.get_sheet(sheet_name) as sheet:
                    rows = []
                    for row in sheet.rows():
                        row_data = [item.v for item in row]
                        if any(v is not None and v != '' for v in row_data):
                            rows.append(row_data)
                    data['sheets'][sheet_name] = rows
                    data['summary'].append({'sheet': sheet_name, 'rows': len(rows)})
            except Exception as e:
                print(f'Error reading {sheet_name}: {e}')

    with open(OUTPUT_FILE, 'w') as f:
        json.dump(data, f, default=str)
    print(f'Saved to {OUTPUT_FILE}')
except Exception as e:
    print(f'Error: {e}')
`

  fs.writeFileSync('/tmp/extract-2023-xlsb.py', pythonScript)

  try {
    execSync('python3 /tmp/extract-2023-xlsb.py', { encoding: 'utf-8' })

    // Read the extracted data
    const xlsbData = JSON.parse(fs.readFileSync('/tmp/burc-2023-all-data.json', 'utf-8'))

    console.log(`   üìã Extracted ${xlsbData.summary.length} sheets from 2023 XLSB:`)
    xlsbData.summary.forEach(s => console.log(`      - ${s.sheet}: ${s.rows} rows`))

    // Sync APAC sheet (main metrics)
    if (xlsbData.sheets['APAC']) {
      await sync2023ApacSheet(xlsbData.sheets['APAC'])
    }

    // Sync Bookings
    if (xlsbData.sheets['Bookings']) {
      await sync2023Bookings(xlsbData.sheets['Bookings'])
    }

    // Sync Dial 2 (pipeline)
    if (xlsbData.sheets['Dial 2']) {
      await sync2023Dial2(xlsbData.sheets['Dial 2'])
    }

    // Sync R&O
    if (xlsbData.sheets['R&O']) {
      await sync2023RO(xlsbData.sheets['R&O'])
    }

    // Sync Overview v Prior (quarterly comparison)
    if (xlsbData.sheets['Overview v Prior']) {
      await sync2023Overview(xlsbData.sheets['Overview v Prior'])
    }

  } catch (err) {
    console.log(`   ‚ùå Python extraction failed: ${err.message}`)
  }
}

async function sync2023ApacSheet(rows) {
  console.log('\n   üìä Syncing 2023 APAC metrics...')

  // APAC sheet contains monthly breakdown similar to APAC BURC in newer files
  const records = []
  const sourceFile = '2023 12 BURC File.xlsb'

  // Find header row with months
  let headerRowIdx = -1
  for (let i = 0; i < 15; i++) {
    const row = rows[i]
    if (row && row.some(cell => MONTHS.some(m => String(cell).includes(m)))) {
      headerRowIdx = i
      break
    }
  }

  if (headerRowIdx === -1) {
    console.log('      Could not find month headers in APAC sheet')
    return
  }

  const headers = rows[headerRowIdx]
  const monthCols = {}
  headers.forEach((h, i) => {
    const hStr = String(h || '').trim()
    MONTHS.forEach((m, mi) => {
      if (hStr.includes(m)) {
        monthCols[mi + 1] = i
      }
    })
  })

  // Extract metrics
  for (let i = headerRowIdx + 1; i < rows.length; i++) {
    const row = rows[i]
    if (!row || !row[0]) continue

    const metricName = String(row[0]).trim()
    if (!metricName || metricName.toLowerCase() === 'total') continue

    for (const [monthNum, colIdx] of Object.entries(monthCols)) {
      const value = parseNumber(row[colIdx])
      if (value === 0) continue

      records.push({
        fiscal_year: 2023,
        month_num: parseInt(monthNum),
        month_name: MONTHS[parseInt(monthNum) - 1],
        metric_name: metricName,
        metric_category: 'APAC Summary',
        value: value,
        source_file: sourceFile
      })
    }
  }

  if (records.length > 0) {
    // De-duplicate records (unique on fiscal_year, month_num, metric_name)
    const consolidated = {}
    for (const rec of records) {
      const key = `${rec.fiscal_year}-${rec.month_num}-${rec.metric_name}`
      if (!consolidated[key]) {
        consolidated[key] = { ...rec }
      } else {
        // Keep the larger value
        if (Math.abs(rec.value) > Math.abs(consolidated[key].value)) {
          consolidated[key].value = rec.value
        }
      }
    }

    const finalRecords = Object.values(consolidated)

    // Insert into burc_monthly_metrics (existing table)
    await supabase.from('burc_monthly_metrics').delete().eq('fiscal_year', 2023)

    const { error } = await supabase.from('burc_monthly_metrics').insert(finalRecords)
    if (error) {
      console.log(`      Error: ${error.message}`)
    } else {
      console.log(`      ‚úÖ Synced ${finalRecords.length} monthly metrics`)
    }
  }
}

async function sync2023Bookings(rows) {
  console.log('\n   üìù Syncing 2023 Bookings...')

  // The Bookings sheet has:
  // Row 12: Account | Dept | Total | Domestic | CAN | EMEA
  // Row 14+: Data rows with account names and values

  const headerRowIdx = rows.findIndex(row =>
    row && row.some(cell =>
      String(cell).toLowerCase().includes('account') ||
      String(cell).toLowerCase().includes('dept')
    )
  )

  if (headerRowIdx === -1) {
    console.log('      Could not find header row')
    return
  }

  console.log(`      Found header at row ${headerRowIdx}`)
  const headers = rows[headerRowIdx].map(h => String(h || '').toLowerCase().trim())
  console.log(`      Headers: ${headers.slice(0, 6).join(', ')}`)

  const accountCol = headers.findIndex(h => h.includes('account'))
  const deptCol = headers.findIndex(h => h.includes('dept'))
  const totalCol = headers.findIndex(h => h.includes('total'))
  const domesticCol = headers.findIndex(h => h.includes('domestic'))

  const records = []

  for (let i = headerRowIdx + 1; i < rows.length; i++) {
    const row = rows[i]
    if (!row) continue

    const accountName = accountCol >= 0 ? String(row[accountCol] || '').trim() : ''
    const dept = deptCol >= 0 ? String(row[deptCol] || '').trim() : ''

    // Skip empty rows and header rows
    if (!accountName || accountName.toLowerCase().includes('total') && !accountName.toLowerCase().includes('software')) continue

    records.push({
      fiscal_year: 2023,
      client_name: dept || null, // Department is often the client/region
      deal_name: accountName,
      sw_amount: 0,
      ps_amount: 0,
      maint_amount: 0,
      total_amount: totalCol >= 0 ? parseNumber(row[totalCol]) : 0,
      category: accountName.includes('Software') ? 'Software' : accountName.includes('Service') ? 'PS' : 'Other',
      source_file: '2023 12 BURC File.xlsb'
    })
  }

  if (records.length > 0) {
    await supabase.from('burc_bookings').delete().eq('fiscal_year', 2023)

    const { error } = await supabase.from('burc_bookings').insert(records)
    if (error) {
      console.log(`      Error: ${error.message}`)
    } else {
      console.log(`      ‚úÖ Synced ${records.length} booking records`)
      stats.bookings += records.length
    }
  } else {
    console.log('      No booking records found')
  }
}

async function sync2023Dial2(rows) {
  console.log('\n   üéØ Syncing 2023 Dial 2 Pipeline...')

  // Already handled by existing sync, but let's ensure it's captured
  const headerRowIdx = rows.findIndex(row =>
    row && row.some(cell =>
      String(cell).toLowerCase().includes('deal') ||
      String(cell).toLowerCase().includes('opportunity')
    )
  )

  if (headerRowIdx === -1) {
    console.log('      No deal headers found')
    return
  }

  // This is already captured by sync-burc-enhanced.mjs
  console.log(`      Already synced via enhanced sync (${rows.length - headerRowIdx - 1} potential deals)`)
}

async function sync2023RO(rows) {
  console.log('\n   ‚ö†Ô∏è Syncing 2023 Risks & Opportunities...')

  const headerRowIdx = rows.findIndex(row =>
    row && row.some(cell =>
      String(cell).toLowerCase().includes('risk') ||
      String(cell).toLowerCase().includes('opportunity') ||
      String(cell).toLowerCase().includes('description')
    )
  )

  if (headerRowIdx === -1) {
    console.log('      Could not find header row')
    return
  }

  const headers = rows[headerRowIdx].map(h => String(h || '').toLowerCase().trim())
  const descCol = headers.findIndex(h => h.includes('description') || h.includes('item'))
  const amountCol = headers.findIndex(h => h.includes('amount') || h.includes('value') || h.includes('impact'))
  const probCol = headers.findIndex(h => h.includes('prob') || h.includes('%'))
  const typeCol = headers.findIndex(h => h.includes('type') || h.includes('category'))

  const records = []

  for (let i = headerRowIdx + 1; i < rows.length; i++) {
    const row = rows[i]
    if (!row) continue

    const desc = descCol >= 0 ? String(row[descCol] || '').trim() : ''
    if (!desc || desc.toLowerCase() === 'total') continue

    // Determine if risk or opportunity based on amount sign or type column
    const amount = amountCol >= 0 ? parseNumber(row[amountCol]) : 0
    let category = typeCol >= 0 ? String(row[typeCol] || '').trim() : ''

    if (!category) {
      category = amount < 0 ? 'Risk' : 'Opportunity'
    }

    records.push({
      fiscal_year: 2023,
      category: category,
      description: desc,
      amount: Math.abs(amount),
      probability: probCol >= 0 ? parseNumber(row[probCol]) : null,
      expected_value: probCol >= 0 && amountCol >= 0 ?
        Math.abs(amount) * (parseNumber(row[probCol]) / 100) : Math.abs(amount),
      source_file: '2023 12 BURC File.xlsb'
    })
  }

  if (records.length > 0) {
    await supabase.from('burc_risks_opportunities').delete().eq('fiscal_year', 2023)

    const { error } = await supabase.from('burc_risks_opportunities').insert(records)
    if (error) {
      console.log(`      Error: ${error.message}`)
    } else {
      console.log(`      ‚úÖ Synced ${records.length} R&O records`)
      stats.risksOpportunities += records.length
    }
  }
}

async function sync2023Overview(rows) {
  console.log('\n   üìä Syncing 2023 Overview v Prior (Quarterly Comparison)...')
  // Similar to quarterly data sync
  // This is already captured by the existing sync
  console.log('      Already synced via enhanced sync')
}

// ============================================================================
// MAIN SYNC FUNCTION
// ============================================================================

async function syncAllWorksheets() {
  console.log('=' .repeat(70))
  console.log('COMPREHENSIVE BURC SYNC - ALL WORKSHEETS')
  console.log('=' .repeat(70))
  console.log(`Started: ${new Date().toISOString()}\n`)

  const files = {
    2026: `${BURC_BASE}/2026/2026 APAC Performance.xlsx`,
    2025: `${BURC_BASE}/2025/2025 APAC Performance.xlsx`,
    2024: `${BURC_BASE}/2024/2024 APAC Performance.xlsx`
  }

  // Process each year's file
  for (const [year, filePath] of Object.entries(files)) {
    if (!fs.existsSync(filePath)) {
      console.log(`\n‚ùå ${year}: File not found`)
      continue
    }

    console.log(`\n${'='.repeat(50)}`)
    console.log(`üìÅ Processing ${year} APAC Performance.xlsx`)
    console.log('='.repeat(50))

    const workbook = XLSX.readFile(filePath)
    const sourceFile = path.basename(filePath)

    console.log(`   Sheets: ${workbook.SheetNames.length}`)

    // Sync all data types
    await syncAttrition(workbook, parseInt(year), sourceFile)
    await syncHeadcount(workbook, parseInt(year), sourceFile)
    await syncMonthlyEbita(workbook, parseInt(year), sourceFile)
    await syncMonthlyOpex(workbook, parseInt(year), sourceFile)
    await syncRevenueDetail(workbook, parseInt(year), sourceFile)
    await syncSupportRenewals(workbook, parseInt(year), sourceFile)
  }

  // Sync 2023 XLSB
  await sync2023Xlsb()

  // Print summary
  console.log('\n' + '='.repeat(70))
  console.log('SYNC COMPLETE - SUMMARY')
  console.log('='.repeat(70))
  console.log(`   Attrition records:       ${stats.attrition}`)
  console.log(`   Headcount records:       ${stats.headcount}`)
  console.log(`   Monthly EBITA records:   ${stats.monthlyEbita}`)
  console.log(`   Monthly OPEX records:    ${stats.monthlyOpex}`)
  console.log(`   Revenue detail records:  ${stats.revenueDetail}`)
  console.log(`   Bookings records:        ${stats.bookings}`)
  console.log(`   R&O records:             ${stats.risksOpportunities}`)
  console.log(`   Support renewals:        ${stats.supportRenewals}`)
  console.log('='.repeat(70))
  console.log(`Total new records: ${Object.values(stats).reduce((a, b) => a + b, 0)}`)
  console.log(`Completed: ${new Date().toISOString()}`)
}

syncAllWorksheets().catch(console.error)
